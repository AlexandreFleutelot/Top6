{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from typing import Any, Dict, Iterable, List\n",
    "from typing_extensions import Self\n",
    "\n",
    "from langchain.schema.retriever import BaseRetriever\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from langchain_core.callbacks.manager import CallbackManagerForRetrieverRun\n",
    "from langchain.schema import Document\n",
    "\n",
    "from langchain.retrievers import BM25Retriever\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Mixed Retriever (Reciprocal Rank Fusion) as retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_score(sparse_score, dense_score, alpha = 0.5):\n",
    "    return (1 - alpha) * sparse_score + alpha * dense_score\n",
    "\n",
    "class HybridRetriever(BaseRetriever):\n",
    "\n",
    "    alpha: float=0.5\n",
    "    sparse_retriever: BM25Retriever\n",
    "    dense_retriever: VectorStoreRetriever\n",
    "\n",
    "    class Config:\n",
    "        \"\"\"Configuration for this pydantic object.\"\"\"\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    @classmethod\n",
    "    def from_texts(cls, texts: Iterable[str], **kwargs: Any, ) -> Self:\n",
    "        sparse_retriever = BM25Retriever.from_texts(texts)\n",
    "        dense_retriever = FAISS.from_texts(texts, embedding=OpenAIEmbeddings()).as_retriever()\n",
    "        return cls(sparse_retriever=sparse_retriever, dense_retriever=dense_retriever)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_documents(cls, documents: Iterable[Document], **kwargs: Any, ) -> Self:\n",
    "        sparse_retriever = BM25Retriever.from_documents(documents)\n",
    "        dense_retriever = FAISS.from_documents(documents, embedding=OpenAIEmbeddings()).as_retriever()\n",
    "        return cls(sparse_retriever=sparse_retriever, dense_retriever=dense_retriever)\n",
    "\n",
    "    def _get_relevant_documents(self,\n",
    "        query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
    "    ) -> List[Document]:\n",
    "        bm25_documents = self.sparse_retriever.get_relevant_documents(query, callbacks=run_manager.get_child())\n",
    "        openai_documents = self.dense_retriever.get_relevant_documents(query, callbacks=run_manager.get_child())\n",
    "        \n",
    "        docs,scores = [] ,[]      \n",
    "        for i,d in enumerate(bm25_documents, start=1):\n",
    "            if d in openai_documents:\n",
    "                rank2 = 1 / (1+openai_documents.index(d))\n",
    "            else: rank2=0\n",
    "            docs.append(d)\n",
    "            scores.append(hybrid_score(1/i, rank2, alpha=self.alpha))\n",
    "\n",
    "        for i,d in enumerate(openai_documents, start=1):\n",
    "            if d not in bm25_documents:\n",
    "                docs.append(d)\n",
    "                scores.append(hybrid_score(0, 1/i, alpha=self.alpha))\n",
    "        \n",
    "        print(self.alpha)\n",
    "        ordered_docs = np.array(docs)[np.argsort(scores)[::-1]]\n",
    "        return list(ordered_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='foo bar'),\n",
       " Document(page_content='foo'),\n",
       " Document(page_content='hello'),\n",
       " Document(page_content='world'),\n",
       " Document(page_content='bar')]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = HybridRetriever.from_documents([\n",
    "        Document(page_content=\"foo\"),\n",
    "        Document(page_content=\"bar\"),\n",
    "        Document(page_content=\"world\"),\n",
    "        Document(page_content=\"hello\"),\n",
    "        Document(page_content=\"foo bar\"),\n",
    "    ])\n",
    "\n",
    "retriever.get_relevant_documents(query=\"fao\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='foo bar'),\n",
       " Document(page_content='hello'),\n",
       " Document(page_content='world'),\n",
       " Document(page_content='bar')]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.sparse_retriever.get_relevant_documents(\"fao\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='foo'),\n",
       " Document(page_content='foo bar'),\n",
       " Document(page_content='hello'),\n",
       " Document(page_content='world')]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.dense_retriever.get_relevant_documents(\"fao\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Cross-Encoder model (as retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEncoderRetriever(BaseRetriever):\n",
    "\n",
    "    model = CrossEncoder('cross-encoder/stsb-TinyBERT-L-4')\n",
    "    docs = []\n",
    "    \n",
    "    class Config:\n",
    "        \"\"\"Configuration for this pydantic object.\"\"\"\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    @classmethod\n",
    "    def from_texts(cls, texts: Iterable[str], **kwargs: Any, ) -> Self:\n",
    "        return cls(docs=texts)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_documents(cls, documents: Iterable[Document], **kwargs: Any, ) -> Self:\n",
    "        return cls(docs=documents)\n",
    "\n",
    "    def _get_relevant_documents(self,\n",
    "        query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
    "    ) -> List[Document]:\n",
    "        searches = [[query, text.page_content] for text in self.docs]\n",
    "        scores = self.model.predict(searches)\n",
    "        ordered_docs = np.array(self.docs)[np.argsort(scores)[::-1]]\n",
    "        return ordered_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Document(page_content='foo'), Document(page_content='foo bar'),\n",
       "       Document(page_content='hello'), Document(page_content='world'),\n",
       "       Document(page_content='bar')], dtype=object)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = CrossEncoderRetriever.from_documents([\n",
    "        Document(page_content=\"foo\"),\n",
    "        Document(page_content=\"bar\"),\n",
    "        Document(page_content=\"world\"),\n",
    "        Document(page_content=\"hello\"),\n",
    "        Document(page_content=\"foo bar\"),\n",
    "    ])\n",
    "\n",
    "retriever.get_relevant_documents(query=\"fooa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Search with CrossEncoder Re-Ranking\n",
    "using langchain implementation of HybridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from sentence_transformers.cross_encoder import CrossEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10564\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader(\"./datasets/kjv.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, \n",
    "    chunk_overlap=50, \n",
    "    separators=\"\\n\"\n",
    "    )\n",
    "docs = text_splitter.split_documents(documents)\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_documents(docs)\n",
    "bm25_retriever.k = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense retriever\n",
    "Based on a local embedding model bge-small-en-v1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = \"./bge-small-en-v1.5\"\n",
    "model_kwargs = {'device':'cuda'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=modelPath, \n",
    "    model_kwargs=model_kwargs, \n",
    "    encode_kwargs=encode_kwargs \n",
    ")\n",
    "\n",
    "faiss_vectorstore = FAISS.from_documents(docs, embedding=embeddings)\n",
    "faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={\"k\": 20})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define de Hybrid Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever], \n",
    "    weights=[0.5, 0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reranking\n",
    "Based on a local crossencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    docs_found = ensemble_retriever.invoke(query)\n",
    "    model_reranker = CrossEncoder('cross-encoder/stsb-TinyBERT-L-4')\n",
    "\n",
    "    searches = [[query, text.page_content] for text in docs_found]\n",
    "    scores = model_reranker.predict(searches)\n",
    "    ordered_docs = np.array(docs_found)[np.argsort(scores)[::-1]]\n",
    "    scores = np.array(scores)[np.argsort(scores)[::-1]]\n",
    "    return ordered_docs, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>page_content='Psa27:6 And now shall mine head ...</td>\n",
       "      <td>0.556627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>page_content='Psa3:3 But thou, O LORD, art a s...</td>\n",
       "      <td>0.451356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>page_content='Dan4:34 And at the end of the da...</td>\n",
       "      <td>0.356573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               score      text\n",
       "0  page_content='Psa27:6 And now shall mine head ...  0.556627\n",
       "1  page_content='Psa3:3 But thou, O LORD, art a s...  0.451356\n",
       "2  page_content='Dan4:34 And at the end of the da...  0.356573"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "scores,ordered_docs = search(\"shall mine head be lifted up above mine enemies\")\n",
    "pd.DataFrame({\"score\":scores, \"text\":ordered_docs}).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>page_content='Psa29:1 Give unto the LORD, O ye...</td>\n",
       "      <td>0.360064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>page_content='Psa29:6 He maketh them also to s...</td>\n",
       "      <td>0.303222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>page_content='Psa31:10 For my life is spent wi...</td>\n",
       "      <td>0.283385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               score      text\n",
       "0  page_content='Psa29:1 Give unto the LORD, O ye...  0.360064\n",
       "1  page_content='Psa29:6 He maketh them also to s...  0.303222\n",
       "2  page_content='Psa31:10 For my life is spent wi...  0.283385"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores,ordered_docs = search(\"Psa29:10\")\n",
    "pd.DataFrame({\"score\":scores, \"text\":ordered_docs}).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Psa44:24 Wherefore hidest thou thy face, and forgettest our affliction and our oppression?\\nPsa44:25 For our soul is bowed down to the dust: our belly cleaveth unto the earth.\\nPsa44:26 Arise for our help, and redeem us for thy mercies' sake.\\nPsa45:1 My heart is inditing a good matter: I speak of the things which I have made touching the king: my tongue is the pen of a ready writer.\", metadata={'source': './datasets/kjv.txt'}),\n",
       " Document(page_content='Psa90:10 The days of our years are threescore years and ten; and if by reason of strength they be fourscore years, yet is their strength labour and sorrow; for it is soon cut off, and we fly away.\\nPsa90:11 Who knoweth the power of thine anger? even according to thy fear, so is thy wrath.\\nPsa90:12 So teach us to number our days, that we may apply our hearts unto wisdom.\\nPsa90:13 Return, O LORD, how long? and let it repent thee concerning thy servants.', metadata={'source': './datasets/kjv.txt'}),\n",
       " Document(page_content='Psa29:1 Give unto the LORD, O ye mighty, give unto the LORD glory and strength.\\nPsa29:2 Give unto the LORD the glory due unto his name; worship the LORD in the beauty of holiness.\\nPsa29:3 The voice of the LORD is upon the waters: the God of glory thundereth: the LORD is upon many waters.\\nPsa29:4 The voice of the LORD is powerful; the voice of the LORD is full of majesty.\\nPsa29:5 The voice of the LORD breaketh the cedars; yea, the LORD breaketh the cedars of Lebanon.', metadata={'source': './datasets/kjv.txt'})]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faiss_retriever.get_relevant_documents(\"Psa29:10\")[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Psa29:6 He maketh them also to skip like a calf; Lebanon and Sirion like a young unicorn.\\nPsa29:7 The voice of the LORD divideth the flames of fire.\\nPsa29:8 The voice of the LORD shaketh the wilderness; the LORD shaketh the wilderness of Kadesh.\\nPsa29:9 The voice of the LORD maketh the hinds to calve, and discovereth the forests: and in his temple doth every one speak of his glory.\\nPsa29:10 The LORD sitteth upon the flood; yea, the LORD sitteth King for ever.', metadata={'source': './datasets/kjv.txt'}),\n",
       " Document(page_content='1Ki19:5 And as he lay and slept under a juniper tree, behold, then an angel touched him, and said unto him, Arise and eat.\\n1Ki19:6 And he looked, and, behold, there was a cake baken on the coals, and a cruse of water at his head. And he did eat and drink, and laid him down again.\\n1Ki19:7 And the angel of the LORD came again the second time, and touched him, and said, Arise and eat; because the journey is too great for thee.', metadata={'source': './datasets/kjv.txt'}),\n",
       " Document(page_content='1Ki18:46 And the hand of the LORD was on Elijah; and he girded up his loins, and ran before Ahab to the entrance of Jezreel.\\n1Ki19:1 And Ahab told Jezebel all that Elijah had done, and withal how he had slain all the prophets with the sword.\\n1Ki19:2 Then Jezebel sent a messenger unto Elijah, saying, So let the gods do to me, and more also, if I make not thy life as the life of one of them by to morrow about this time.', metadata={'source': './datasets/kjv.txt'})]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_retriever.get_relevant_documents(\"Psa29:10\")[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
